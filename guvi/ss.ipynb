{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install webdriver-manager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error clicking 'Load More' button: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/div[2]/div/span/button/span/span\"}\n",
      "  (Session info: chrome=134.0.6998.166); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6121D4C25+3179557]\n",
      "\t(No symbol) [0x00007FF611E388A0]\n",
      "\t(No symbol) [0x00007FF611CC91CA]\n",
      "\t(No symbol) [0x00007FF611D1FA67]\n",
      "\t(No symbol) [0x00007FF611D1FC9C]\n",
      "\t(No symbol) [0x00007FF611D73627]\n",
      "\t(No symbol) [0x00007FF611D47C6F]\n",
      "\t(No symbol) [0x00007FF611D702F3]\n",
      "\t(No symbol) [0x00007FF611D47A03]\n",
      "\t(No symbol) [0x00007FF611D106D0]\n",
      "\t(No symbol) [0x00007FF611D11983]\n",
      "\tGetHandleVerifier [0x00007FF6122367CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF61224D1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF612242153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF611FA092A+868650]\n",
      "\t(No symbol) [0x00007FF611E42FFF]\n",
      "\t(No symbol) [0x00007FF611E3F4A4]\n",
      "\t(No symbol) [0x00007FF611E3F646]\n",
      "\t(No symbol) [0x00007FF611E2EAA9]\n",
      "\tBaseThreadInitThunk [0x00007FF9D50F259D+29]\n",
      "\tRtlUserThreadStart [0x00007FF9D632AF38+40]\n",
      "\n",
      "No more content to load.\n",
      "No more pages. Scraping complete.\n",
      "Scraped 3 movies successfully! File saved as: imdb_2024_movies_game-show.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from selenium.webdriver.common.action_chains import ActionChains  # Import ActionChains\n",
    "\n",
    "# Initialize WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "url = \"https://www.imdb.com/search/title/?title_type=feature&release_date=2024-01-01,2024-12-31&genres=game-show\"\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the first page to load\n",
    "time.sleep(3)\n",
    "\n",
    "# Lists to store movie details\n",
    "titles, ratings, votings, durations = [], [], [], []\n",
    "\n",
    "# Define click_load_more function BEFORE using it\n",
    "def click_load_more(): \n",
    "    try: \n",
    "        load_more_button = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/div[2]/div/span/button/span/span')\n",
    "        ActionChains(driver).move_to_element(load_more_button).perform()  # Scroll to the button\n",
    "        load_more_button.click()\n",
    "        time.sleep(3)  # Allow content to load\n",
    "        return True \n",
    "    except Exception as e: \n",
    "        print(\"Error clicking 'Load More' button:\", e) \n",
    "        return False \n",
    "\n",
    "# Main scraping loop\n",
    "while True:\n",
    "    try:\n",
    "        # Wait for movies to load\n",
    "        WebDriverWait(driver, 10).until(              #//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/div[2]/div/span/button/span\n",
    "            EC.presence_of_element_located((By.XPATH, '//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/ul/li'))\n",
    "        )\n",
    "\n",
    "        # Click \"Load More\" until no more content appears\n",
    "        while click_load_more(): \n",
    "            print(\"Clicked 'Load More' button\")\n",
    "        print(\"No more content to load.\")\n",
    "\n",
    "        # Scroll to bottom to load all content\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)  # Allow content to load\n",
    "\n",
    "        # Get movie elements\n",
    "        movie_items = driver.find_elements(By.XPATH, '//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/ul/li')\n",
    "\n",
    "        for movie_item in movie_items:\n",
    "            try:\n",
    "                # Extract movie title\n",
    "                title = movie_item.find_element(By.XPATH, './/div/div/div/div[1]/div[2]/div[1]/a/h3').text\n",
    "\n",
    "                # Extract rating (handle missing values)\n",
    "                rating = movie_item.find_element(By.XPATH, './/div/div/div/div[1]/div[2]/span/div/span/span[1]').text if movie_item.find_elements(By.XPATH, './/div/div/div/div[1]/div[2]/span/div/span/span[1]') else \"N/A\"\n",
    "\n",
    "                # Extract voting (handle missing values)\n",
    "                voting = movie_item.find_element(By.XPATH, './/div/div/div/div[1]/div[2]/span/div/span/span[2]').text if movie_item.find_elements(By.XPATH, './/div/div/div/div[1]/div[2]/span/div/span/span[2]') else \"N/A\"\n",
    "\n",
    "                # Extract duration (handle missing values)\n",
    "                duration = movie_item.find_element(By.XPATH, './/div/div/div/div[1]/div[2]/div[2]/span[2]').text if movie_item.find_elements(By.XPATH, './/div/div/div/div[1]/div[2]/div[2]/span[2]') else \"N/A\"\n",
    "\n",
    "                # Append to lists (avoid duplicates)\n",
    "                if title not in titles:\n",
    "                    titles.append(title)\n",
    "                    ratings.append(rating)\n",
    "                    votings.append(voting)\n",
    "                    durations.append(duration)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting a movie: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Try clicking the \"Next Page\" button\n",
    "        try:\n",
    "            next_button_xpath = '//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/div[2]/div/span/button/span/span'\n",
    "            next_button = WebDriverWait(driver, 5).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, next_button_xpath))\n",
    "            )\n",
    "\n",
    "            # Scroll to \"Next\" button and click it\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView();\", next_button)\n",
    "            time.sleep(1)  # Small delay before clicking\n",
    "            next_button.click()\n",
    "            time.sleep(5)  # Allow new page content to load\n",
    "\n",
    "        except (TimeoutException, NoSuchElementException):\n",
    "            print(\"No more pages. Scraping complete.\")\n",
    "            break  # Exit loop if Next button is unavailable\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error navigating pages: {e}\")\n",
    "        break  # Break on major errors\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Title': titles, \n",
    "    'Rating': ratings,\n",
    "    'Votes': votings,\n",
    "    'Duration': durations\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "file_path = \"imdb_2024_movies_game-show.csv\"\n",
    "df.to_csv(file_path, index=False, mode=\"w\", encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Scraped {len(df)} movies successfully! File saved as: {file_path}\")\n",
    "\n",
    "# Close browser\n",
    "driver.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Title  Rating     Votes Duration   genre\n",
      "0          1. Kraven the Hunter     5.4   46000.0    2h 7m  action\n",
      "1                   2. Twisters     6.5  161000.0    2h 2m  action\n",
      "2               3. Gladiator II     6.5  218000.0   2h 28m  action\n",
      "3       4. Sonic the Hedgehog 3     6.9   53000.0   1h 50m  action\n",
      "4  5. Pushpa: The Rule - Part 2     6.1   54000.0   3h 21m  action\n",
      "Merged CSV saved at: C:\\Users\\SIBI\\OneDrive\\Desktop\\web_Scraping_selenium (2)\\web_Scraping_selenium\\guvi\\all_movies_2024.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Path where genre-wise CSVs are stored\n",
    "csv_folder = r\"C:\\Users\\SIBI\\OneDrive\\Desktop\\web_Scraping_selenium (2)\\web_Scraping_selenium\\guvi\"\n",
    "\n",
    "# Get all CSV file names\n",
    "csv_files = [f for f in os.listdir(csv_folder) if f.endswith('.csv')]\n",
    "\n",
    "# Read and merge all CSVs with genre information\n",
    "df_list = []\n",
    "\n",
    "for file in csv_files:\n",
    "    genre_name = os.path.splitext(file)[0]  # Extract genre from filename\n",
    "    df = pd.read_csv(os.path.join(csv_folder, file))\n",
    "    df['genre'] = genre_name  # Add genre column\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "merged_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Remove duplicates (if necessary)\n",
    "merged_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Save merged data\n",
    "output_file = os.path.join(csv_folder, \"all_movies_2024.csv\")\n",
    "merged_df.to_csv(output_file, index=False)\n",
    "\n",
    "# Display the first few rows\n",
    "print(merged_df.head())\n",
    "\n",
    "print(f\"Merged CSV saved at: {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Title        genre  Rating Votes Duration\n",
      "0        1500. Opioids: The Hidden Crisis  documentary    10.0   9.0     None\n",
      "1  2516. Retratos de RepÃºblica Dominicana  documentary    10.0   9.0    1h 1m\n",
      "2                      1010. The Premiere       comedy    10.0   8.0   1h 46m\n",
      "3                        366. Clownface 3       action    10.0  34.0   1h 44m\n",
      "4                        389. Clownface 3       horror    10.0  34.0   1h 44m\n",
      "5                        156. Clownface 3      mystery    10.0  34.0   1h 44m\n",
      "6                        616. Clownface 3     thriller    10.0  34.0   1h 44m\n",
      "7                       437. Mashaarojinn       horror    10.0  18.0   1h 39m\n",
      "8         65. Ice Cross: Life on the Edge        sport    10.0  11.0   1h 30m\n",
      "9                 491. Azotes de Barrio 2       action     9.9   8.0     None\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to SQLite database\n",
    "conn = sqlite3.connect(\"movies_2024.db\")\n",
    "\n",
    "# Query to get unique movies with their proper information\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT Title, genre, Rating, Votes, Duration \n",
    "FROM movies\n",
    "WHERE genre != 'all_movies_2024'  -- Filter out the incorrect genre\n",
    "ORDER BY Rating DESC, Votes DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "top_movies = pd.read_sql(query, conn)\n",
    "print(top_movies)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 12:49:21.431 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-31 12:49:21.434 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-31 12:49:21.437 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-31 12:49:21.437 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-31 12:49:21.443 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-31 12:49:21.444 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-31 12:49:21.447 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-31 12:49:21.452 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-31 12:49:21.454 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# Connect to SQLite database\n",
    "def load_data():\n",
    "    conn = sqlite3.connect(\"movies_2024.db\")\n",
    "    df = pd.read_sql(\"SELECT * FROM movies\", conn)\n",
    "    conn.close()\n",
    "    return df\n",
    "\n",
    "df = load_data()\n",
    "\n",
    "st.title(\"IMDb 2024 Movies Analysis ðŸŽ¬\")\n",
    "st.sidebar.header(\"Filter Options\")\n",
    "\n",
    "# Genre selection\n",
    "selected_genre = st.sidebar.selectbox(\"Select Genre\", [\"All\"] + sorted(df[\"genre\"].unique()))\n",
    "if selected_genre != \"All\":\n",
    "    df = df[df[\"genre\"] == selected_genre]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
